Testing Web Services (WS) for robustness is a lengthy and arduous process. After testing a set of services, there is typically a very large quantity and variety of test results to be analyzed, which poses a challenge to the developer that has to manually process all results and identify the out-puts that indicate the presence of bugs in the code. Previous research indicates that well-known automatic classification algorithms can be used to automate this step. However, the applicability of such algorithms is also limited, as they are frequently unable to deal with the large diversity of outputs present in typical WS scenarios, thus producing incorrect results. In this paper we propose an approach that allows the automatic classification of the results of WS robustness tests. The technique integrates rule-based classification (including domain rules) and conventional machine-learning algorithms trained using generic data. The proposed approach was used to classify a large set of results of tests performed over publicly available WS and also over in-house implementations of several TPC benchmarks. Results show the effectiveness of the technique, indicating that it can be integrated in the robustness testing procedure, enabling, in this way, the delivery of a full end-to-end automatic approach for WSs robustness testing.