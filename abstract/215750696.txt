A major goal of the On-The-Fly Computing project is the automated composition of individual services based on services that are available in dynamic markets. Dependent on the granularity of a market, different alternatives that satisfy the requested functional requirements may emerge. In order to select the best solution, services are usually selected with respect to their quality in terms of inherent non-functional properties. In this paper, we describe our idea of how to model this service selection process as a Markov Decision Process, which we in turn intend to solve by means of Reinforcement Learning techniques in order to control the underlying service composition process. In addition, some initial issues with respect to our approach are addressed.